```{r}
#| include: false
#| label: module-5-first-chunk
```

## The Tidymodels Framework {.smaller}

[![](images/tidymodels-hex-logo.png){style="width: 120px;"}](https://www.tidymodels.org/)

The Tidymodels framework is a collection of packages for modeling and machine learning using [Tidyverse](https://www.tidyverse.org/) principles.

It is created by the same team that developed the `tidyverse` and is designed to work seamlessly with it.

Although it is a relative newcomer to the R ecosystem (2018), it has quickly gained popularity due to its simplicity and consistency.

::: {.notes}
:::

## Tidymodels Packages {.smaller}

Like Tidyverse, Tidymodels also has a meta-package that installs or load the most important packages from the collection.

:::: {.columns}
::: {.column style="width: 50%; padding-top: 10px; padding-bottom: 10px;"}
```r
install.packages("tidymodels")
```
:::
::: {.column style="width: 50%; padding-top: 10px; padding-bottom: 10px;"}
```r
library("tidymodels")
```
:::
::::

::: {style="font-size: 1em;"}
- `rsample`: Provides infrastructure for efficient data splitting and resampling.
- `parsnip`: A tidy, unified interface to models.
- `recipes`: A tidy interface to data pre-processing tools for feature engineering.
- `workflows`: A package to bundle the pre-processing, modeling, and post-processing together.
- `infer`: A statistical **grammar** for inferential statistics.
:::

::: {.notes}
:::

## Power Analysis {.smaller}

::: {style="padding-top: 100px;"}
```{r}
#| echo: false

dplyr::tibble(
  decision = c("Accept", "Reject"),
  h0_true = c(
    "Correct inference<br>(True negative)<br>($1 - \\alpha$)",
    "Type I error<br>(False positive)<br>($\\alpha$)"
  ),
  h0_false = c(
    "Type II error<br>(False negative)<br>($\\beta$)",
    "Correct inference<br>(True positive)<br>($1 - \\beta$)"
  )
) |>
  gt::gt() |>
  gt::tab_options(
    table.width = gt::pct(70),
    table.font.size = gt::pct(80)
  ) |>
  gt::cols_label(
    decision = gt::md("Decision about $\\text{H}_{0}$"),
    h0_true = gt::md("$\\text{H}_{0}$ True"),
    h0_false = gt::md("$\\text{H}_{0}$ False")
  ) |>
  gt::cols_align(
    align = "center",
    columns = c(decision, h0_true, h0_false)
  ) |>
  # gt::cols_width(
  #   gt::starts_with("decision") ~ gt::px(200),
  #   gt::everything() ~ gt::px(300)
  # ) |>
  gt::tab_options(column_labels.font.weight = "bold") |>
  gt::fmt_markdown(columns = gt::everything()) |>
  gt::tab_style(
    style = gt::cell_text(weight = "bold"),
    locations = gt::cells_body(
      columns = decision,
      rows = gt::everything()
    )
  ) |>
  gt::tab_style(
    style = gt::cell_text(align = "center"),
    locations = gt::cells_body(columns = c(decision, h0_true, h0_false))
  ) |>
  gt::data_color(
    columns = "h0_true",
    rows = 1,
    palette = brandr::get_brand_color_tint(900, "green")
  )  |>
  gt::data_color(
    columns = "h0_true",
    rows = 2,
    palette = brandr::get_brand_color_tint(900, "red")
  )  |>
  gt::data_color(
    columns = "h0_false",
    rows = 1,
    palette = brandr::get_brand_color_tint(900, "red")
  )  |>
  gt::data_color(
    columns = "h0_false",
    rows = 2,
    palette = brandr::get_brand_color_tint(900, "green")
  )
```
:::

::: footer
(Based on @casella2002[p. 383])
:::

::: {.notes}
:::

## Power Analysis {.smaller .nostretch}

```{r}
#| code-fold: true
#| warning: false
#| fig-align: center

library(pwrss)

pwr_analysis <- pwrss.t.2means(
  mu1 = 0.2, # Cohen's d for small effect sizes
  mu2 = 0,
  power = 0.8,
  alpha = 0.05,
  welch.df = TRUE,
  alternative = "greater"
)

power.t.test(
  ncp = pwr_analysis$ncp,
  df = pwr_analysis$df,
  alpha = pwr_analysis$parms$alpha,
  alternative = "greater",
  plot = TRUE,
  verbose = FALSE
)
```

::: {.notes}
:::

## Power Analysis {.smaller .nostretch}

```{r}
#| code-fold: true
#| warning: false
#| fig-align: center

library(pwrss)

pwr_analysis <- pwrss.t.2means(
  mu1 = 0.2, # Cohen's d for small effect sizes
  mu2 = 0,
  power = 0.3,
  alpha = 0.05,
  welch.df = TRUE,
  alternative = "greater",
)

power.t.test(
  ncp = pwr_analysis$ncp,
  df = pwr_analysis$df,
  alpha = pwr_analysis$parms$alpha,
  alternative = "greater",
  plot = TRUE,
  verbose = FALSE
)
```

::: {.notes}
:::

## Power Analysis {.smaller .nostretch}

```{r}
#| code-fold: true
#| warning: false
#| fig-align: center

library(pwrss)

pwr_analysis <- pwrss.t.2means(
  mu1 = 0.2, # Cohen's d for small effect sizes
  mu2 = 0,
  power = 0.999,
  alpha = 0.001,
  welch.df = TRUE,
  alternative = "greater",
)

power.t.test(
  ncp = pwr_analysis$ncp,
  df = pwr_analysis$df,
  alpha = pwr_analysis$parms$alpha,
  alternative = "greater",
  plot = TRUE,
  verbose = FALSE
)
```

::: {.notes}
:::

## Type I Errors ($\alpha$) {.smaller .nostretch data-menu-title="Type I Errors"}

![](images/allison-horst-figure-39.png){fig-align="center" style="width: 90%; padding-top: 0px;"}

::: footer
(Artwork by [Allison Horst](https://twitter.com/allison_horst))
:::

::: {.notes}
:::

## Type II Errors ($\beta$) {.smaller data-menu-title="Type II Errors"}

![](images/allison-horst-figure-40.png){fig-align="center" style="width: 90%; padding-top: 30px;"}

::: footer
(Artwork by [Allison Horst](https://twitter.com/allison_horst))
:::

::: {.notes}
:::

## The *p*-value Problem {.smaller}

::::: {.columns}
:::: {.column style="width: 40%; padding-top: 0px;"}
Large samples and sensitivity

Is a difference of $0.00001$ valid?

Statistical ritual *versus* Statistical thinking

::: {style="font-size: 0.5em; font-style: italic; padding-top: 15px;"}
Comparison of a 95% of confidence level ($\alpha = 0.05$) and an *n*-dependent *p-value* curve. The parameter $n_{\alpha}$ represents the minimum sample size to detect statistically significant differences among compared groups. The parameter $n_{\gamma}$ represents the convergence point of the *p-value* curve. When the *p-value* curve expresses practical differences, the area under the red curve ($A_{p(n)}$) is smaller than the area under the constant function $\alpha = 0.05$ ($A_{\alpha = 0.05}$) when it is evaluated between $0$ and $n_{\gamma}$.
:::
::::
:::: {.column style="width: 60%; padding-top: 100px;"}
![](images/gomez-de-mariscal-2021-figure-3.png){fig-align="center" style="width: 75%; padding-top: 0px;"}
::::
:::::

::: footer
(Reproduced from @mariscal2021[Figure 3])
:::

::: {.notes}
:::

## Cohen's Benchmark {.smaller}

:::: {.columns}
::: {.column style="width: 50%;"}
> [...] in many circumstances, all that is intended by "proving" the null hypothesis is that the ES [Effect Size] is not necessarily zero but **small enough to be negligible**`<br>`{=html}[@cohen1988a, p. 461].
:::
::: {.column style="width: 50%;"}
![](images/jacob-cohen-figure-1.jpg){fig-align="center" style="width: 80%; padding-top: 25px;"}
:::
::::

::: footer
(Photo by an unknown author.)
:::

::: {.notes}
:::

## Cohen's Benchmark {.smaller}

```{r}
#| echo: false

dplyr::tibble(
  test = c(
    "Comparison of independent means", "Comparison of two correlations",
    "Difference between proportions", "Correlation", "", "Crosstabulation",
    "ANOVA", "", "Multiple regression", ""
  ),
  relevant_effect_size = c(
    "$d$, $\\Delta$, Hedges’ $g$", "$q$", "Cohen’s $g$", "$r$", "$r^{2}$",
    "$w$, $\\varphi$, $V$, $C$", "$f$", "$\\eta^{2}$", "$R^{2}$", "$f^{2}$"
  ),
  small = c(.20, .10, .05, .10, .01, .10, .10, .01, .02, .02),
  medium = c(.50, .30, .15, .30, .09, .30, .25, .06, .13, .15),
  large = c(.80, .50, .25, .50, .25, .50, .40, .14, .26, .35)
) |>
  gt::gt() |>
  gt::tab_options(table.font.size = gt::pct(50)) |>
  gt::cols_label(
    test = "Test",
    relevant_effect_size = "Relevant Effect Size",
    small = "Small",
    medium = "Medium",
    large = "Large"
  ) |>
  gt::fmt_markdown(columns = relevant_effect_size) |>
  gt::tab_spanner(
    label = "Effect Size Classes",
    columns = c(small, medium, large)
  ) |>
  gt::tab_source_note(
    source_note = gt::md(
      paste0(
        "Notes: The rationale for most of these benchmarks can be found ",
        "in Cohen (1988) at the following pages: Cohen’s $d$ (p. 40), ",
        "$q$ (p. 115), Cohen’s $g$ (pp. 147–149), $r$ and $r^{2}$ ",
        "(pp. 79–80), Cohen’s $w$ (pp. 224–227), $f$ and $\\eta^{2}$ ",
        "(pp. 285–287), $R^{2}$ and $f^{2}$ (pp. 413–414)."
      )
    )
  ) |>
  gt::cols_align(
    align = "center",
    columns = c(small, medium, large)
  ) |>
  gt::tab_style(
    style = gt::cell_text(weight = "bold"),
    locations = gt::cells_column_spanners()
  ) |>
  gt::tab_style(
    style = gt::cell_text(weight = "bold"),
    locations = gt::cells_column_labels(gt::everything())
  )
```

::: footer
(Adapted from @ellis2010. Based on @cohen1988a)
:::

::: {.notes}
:::

## The *p*-value Problem: Example {.smaller}

::::: {.columns}
:::: {.column style="width: 45%; font-size: 0.9em;"}
$\Delta\text{R}^{2}$ = 0.00388`<br>`{=html}Cohen’s $f^{2}$ = 0.00414

Latitudinal cline of chronotype [@leocadio-miguel2017].

[Critique](https://danielvartan.github.io/mastersthesis/web/qmd/supplementary-material-9.html) of Leocadio-Miguel et al. latitude article [@vartanian2025a].

The ASA statement on p-values [@wasserstein2016].

Authors who rely solely on the p-value demonstrate a preference for statistical rituals over statistical reasoning [@gigerenzer2004].
::::
:::: {.column style="width: 55%;"}
![](images/leocadio-miguel-2017-figure-2.png){fig-align="center" style="width: 100%; padding-top: 25px;"}

::: {style="font-size: 0.5em; padding-left: 35px; padding-right: 15px;"}
**Note**: The HO score [@horne1976] goes from 16 to 86, with higher scores indicating a preference for morningness.
:::
::::
:::::

::: footer
(Reproduced from @leocadio-miguel2017[Figure 2])
:::

::: {.notes}
:::

## What Test Should I Use? {.smaller .nostretch}

Check Antoine Soetewey's [flowchart](https://statsandr.com/blog/what-statistical-test-should-i-do/) to help you decide the appropriate statistical test for your data.

![](images/soetewey-2021-flowchart.svg){fig-align="center" style="width: 65%; padding-top: 0px;"}

::: footer
(Artwork by [Antoine Soetewey](https://statsandr.com/blog/what-statistical-test-should-i-do/))
:::

::: {.notes}
:::

## `infer` Pipeline Examples {.smaller .nostretch}

[![](images/infer-hex-logo.png){style="width: 120px;"}](https://readr.tidyverse.org/)

`infer` is a [Tidymodels](https://www.tidymodels.org/) package that provides a statistical **grammar** for inferential statistics.

It also offers [pipeline examples](https://infer.tidymodels.org/articles/observed_stat_examples.html) for various hypothesis tests. These pipelines can serve as a helpful starting point for implementing other types of models.

::: {.notes}
:::

## ⚠️ Warning ⚠️ {.smaller}

**The examples provided here are for educational purposes only**.

In these examples, we are not verifying the assumptions underlying the statistical tests. For simplicity, we assume that the data satisfies all necessary assumptions, and the resulting models are valid.

Please note that **the results of the statistical tests might not be valid** due to these simplifications.

In practice, always ensure that the assumptions of the statistical tests you use are thoroughly checked and validated.

::: {.notes}
:::

## t-Test: Hypothesis {.smaller}

:::: {.columns}
::: {.column style="width: 50%; font-size: 0.85em;"}
[Is there a meaningful difference in flipper length between Adelie and Gentoo penguins?]{style="font-size: 1.1em; font-weight: bold; color: #ED6B4D;"}

To test this, we will perform a **t-Test for Independent Samples** using a randomization-based empirical null distribution approach.

To ensure [practical significance]{style="text-decoration: underline;"}, we will analyze the difference in means for its effect size, considering a 95% confidence interval.

Cohen's benchmark for a small effect size will be used as our Minimum Effect Size (MES) [@cohen1988a].
:::
::: {.column style="width: 50%; padding-top: 130px;"}
$$
\begin{cases}
\text{H}_{0}: \mu_{A} = \mu_{B} \\
\text{H}_{a}: \mu_{A} \neq \mu_{B} \\
\end{cases}
$$

$$
\begin{cases}
\text{H}_{0}: d < \text{MES} \\
\text{H}_{a}: d \geq \text{MES} \\
\end{cases}
$$
:::
::::

::: {.notes}
:::

## t-Test: Boxplots {.smaller}

```{r}
#| fig-align: center
#| code-fold: true
#| warning: false

library(brandr)
library(dplyr)
library(ggplot2)
library(palmerpenguins)
library(tidyr)

penguins |>
  filter(species %in% c("Adelie", "Gentoo")) |>
  drop_na(flipper_length_mm, species) |>
  ggplot(aes(x = species, y = flipper_length_mm, fill = species)) +
  geom_boxplot(outlier.color = get_brand_color("dark-red")) +
  geom_jitter(width = 0.2, alpha = 0.1) +
  scale_fill_brand_d(alpha = 0.7) +
  labs(x = "Species", y = "Flipper Length (mm)", fill = "Species")
```

::: {.notes}
:::

## t-Test: Density Plots {.smaller}

```{r}
#| fig-align: center
#| code-fold: true

library(brandr)
library(dplyr)
library(ggplot2)
library(palmerpenguins)
library(tidyr)

penguins |>
  filter(species %in% c("Adelie", "Gentoo")) |>
  drop_na(flipper_length_mm, species) |>
  ggplot(aes(x = flipper_length_mm, fill = species)) +
  geom_density(alpha = 0.7) +
  scale_fill_brand_d() +
  labs(x = "Flipper Length (mm)", y = "Density", fill = "Species")
```

::: {.notes}
:::

## t-Test: Power Analysis {.smaller}

```{r}
library(dplyr)
library(palmerpenguins)
library(tidyr)
```

```{r}
penguins |>
  filter(species %in% c("Adelie")) |>
  drop_na(flipper_length_mm, species) |>
  nrow()
```

```{r}
penguins |>
  filter(species %in% c("Gentoo")) |>
  drop_na(flipper_length_mm, species) |>
  nrow()
```

::: {.notes}
:::

## t-Test: Power Analysis {.smaller}

```{r}
library(pwr)
```

```{r}
pwr_analysis <- pwr.t.test(
  d = 0.2, # Cohen's d for small effect sizes
  sig.level = 0.05,
  power = 0.8,
  type = "two.sample",
  alternative = "two.sided"
)

pwr_analysis
```

::: {.notes}
:::

## t-Test: Power Analysis {.smaller}

```{r}
library(pwr)
```

```{r}
pwr_analysis <- pwr.t.test(
  d = 0.5, # Cohen's d for medium effect sizes
  sig.level = 0.05,
  power = 0.8,
  type = "two.sample",
  alternative = "two.sided"
)

pwr_analysis
```

::: {.notes}
:::

## t-Test: Power Analysis {.smaller}

```{r}
#| code-fold: true
#| warning: false
#| fig-align: center

library(pwr)

pwr_analysis |>
  plot.power.htest(
    xlab = "Sample Size Per Group",
    ylab = "Power (1 - Beta)",
    main = NULL
  )
```

::: {.notes}
:::

## t-Test: Observed Statistic {.smaller}

```{r}
library(dplyr)
library(infer)
library(palmerpenguins)
library(tidyr)
```

```{r}
observed_statistic <-
  penguins |>
  filter(species %in% c("Gentoo", "Adelie")) |>
  drop_na(flipper_length_mm, species) |>
  specify(flipper_length_mm ~ species) |>
  hypothesize(null = "independence") |>
  calculate(stat = "t", order = c("Gentoo", "Adelie"))

observed_statistic
```

::: {.notes}
:::

## t-Test: Null Distribution {.smaller}

```{r}
library(dplyr)
library(infer)
library(palmerpenguins)
library(tidyr)
```

```{r}
null_dist <-
  penguins |>
  filter(species %in% c("Gentoo", "Adelie")) |>
  drop_na(flipper_length_mm, species) |>
  specify(flipper_length_mm ~ species) |>
  hypothesize(null = "independence") |>
  generate(reps = 1000, type = "permute") |>
  calculate(stat = "t", order = c("Gentoo", "Adelie"))

null_dist
```

::: {.notes}
:::

## t-Test: Visualizing {.smaller}

```{r}
#| code-fold: true
#| fig-align: center
#| fig-height: 7
#| fig-width: 15

library(infer)
library(ggplot2)

null_dist |>
  visualize() +
  shade_p_value(obs_stat = observed_statistic, direction = "two-sided") +
  labs(
    title = NULL,
    x = "t-statistic",
    y = "Frequency"
  ) +
  theme(text = element_text(size = 14))
```

::: {.notes}
:::

## t-Test: p-value {.smaller}

```{r}
#| warning: false

null_dist |>
  get_p_value(obs_stat = observed_statistic, direction = "two-sided")
```

::: {.notes}
:::

## t-Test: Effect Size {.smaller}

:::: {.columns}
::: {.column style="width: 50%;"}
```{r}
library(dplyr)
library(effectsize)
library(palmerpenguins)
library(tidyr)
```

```{r}
adelie <-
  penguins |>
  filter(species == "Adelie") |>
  drop_na() |>
  pull(flipper_length_mm)

gentoo <-
  penguins |>
  filter(species == "Gentoo") |>
  drop_na() |>
  pull(flipper_length_mm)
```
:::
::: {.column style="width: 50%;"}
```{r}
effect_size <-
  cohens_d(
    x = gentoo,
    y = adelie,
    mu = 0,
    ci = 0.95,
    alternative = "two.sided"
  )

effect_size
```
:::
::::

::: {style="padding-top: 15px;"}
```{r}
effect_size |> interpret_hedges_g(rules = "cohen1988")
```
:::

::: {.notes}
:::

## t-Test: Power Analysis {.smaller}

```{r}
library(pwrss)
```

```{r}
#| warning: false

pwr_analysis <- pwrss.t.2means(
  mu1 = gentoo |> mean(na.rm = TRUE),
  mu2 = adelie |> mean(na.rm = TRUE),
  sd1 = gentoo |> sd(na.rm = TRUE),
  sd2 = adelie |> sd(na.rm = TRUE),
  paired = FALSE,
  n2 = length(adelie),
  kappa = length(gentoo) / length(adelie),
  power = NULL,
  alpha = 0.05,
  welch.df = TRUE,
  alternative = "not equal"
)
```

::: {.notes}
:::

## t-Test: Power Analysis {.smaller}

```{r}
#| code-fold: true
#| warning: false
#| fig-align: center

library(pwrss)

power.t.test(
  ncp = pwr_analysis$ncp,
  df = pwr_analysis$df,
  alpha = 0.05,
  alternative = "not equal",
  plot = TRUE,
  verbose = FALSE
)
```

::: {.notes}
:::

## t-Test: Conclusion {.smaller}

:::: {.columns}
::: {.column style="width: 60%; font-size: 0.85em;"}
[Is there a meaningful difference in flipper length between Adelie and Gentoo penguins?]{style="font-size: 1.1em; font-weight: bold; color: #ED6B4D;"}

Our analysis found a statistically significant difference in means ($t$ = 34.4, $p$-value < 0.001). The observed effect size was very large and exceed the Minimal Effect Size (MES) threshold ($d$ = 4.13, 95% CI [3.70, 4.56]).

The power (1 - $\beta$) of the test is 1, indicating that the probability of a false negative is zero.

Based on these results, we conclude that **there is a meaningful difference in flipper length between Adelie and Gentoo penguins**, with Gentoo penguins having significantly longer flippers. Consequently, we reject the null hypothesis in favor of the alternative hypothesis.
:::
::: {.column style="width: 40%; padding-top: 130px;"}
$$
\begin{cases}
\text{H}_{0}: \mu_{A} = \mu_{B} \\
\text{H}_{a}: \mu_{A} \neq \mu_{B} \\
\end{cases}
$$

$$
\begin{cases}
\text{H}_{0}: d < \text{MES} \\
\text{H}_{a}: d \geq \text{MES} \\
\end{cases}
$$
:::
::::

::: {.notes}
:::

## ANOVA: Hypothesis {.smaller}

:::: {.columns}
::: {.column style="width: 50%; font-size: 0.85em;"}
[Is there a meaningful difference in flipper length between Adelie, Chinstrap, and Gentoo penguins?]{style="font-size: 1.1em; font-weight: bold; color: #ED6B4D;"}

To test this, we will perform a **One-Way ANOVA** using a randomization-based empirical null distribution approach.

To ensure [practical significance]{style="text-decoration: underline;"}, we will analyze the difference in means for its effect size, considering a 95% confidence interval.

Cohen's benchmark for a small effect size will be used as our Minimum Effect Size (MES) [@cohen1988a].
:::
::: {.column style="width: 50%; padding-top: 125px;"}
$$
\begin{cases}
\text{H}_{0}: \mu_{A} = \mu_{B} = \mu_{C} \\
\text{H}_{a}: \mu_{i} \neq \mu_{j}, \ \text{for some} \ i, j
\end{cases}
$$

$$
\begin{cases}
\text{H}_{0}: f < \text{MES} \\
\text{H}_{a}: f \geq \text{MES} \\
\end{cases}
$$
:::
::::

::: {.notes}
:::

## ANOVA: Boxplots {.smaller}

```{r}
#| fig-align: center
#| code-fold: true
#| warning: false

library(brandr)
library(ggplot2)
library(palmerpenguins)
library(tidyr)

penguins |>
  drop_na(flipper_length_mm, species) |>
  ggplot(aes(x = species, y = flipper_length_mm, fill = species)) +
  geom_boxplot(outlier.color = get_brand_color("dark-red")) +
  geom_jitter(width = 0.2, alpha = 0.1) +
  scale_fill_brand_d(alpha = 0.7) +
  labs(x = "Species", y = "Flipper Length (mm)", fill = "Species")
```

::: {.notes}
:::

## ANOVA: Density Plots {.smaller}

```{r}
#| fig-align: center
#| code-fold: true

library(brandr)
library(ggplot2)
library(palmerpenguins)
library(tidyr)

penguins |>
  drop_na(flipper_length_mm, species) |>
  ggplot(aes(x = flipper_length_mm, fill = species)) +
  geom_density(alpha = 0.7) +
  scale_fill_brand_d() +
  labs(x = "Flipper Length (mm)", y = "Density", fill = "Species")
```

::: {.notes}
:::

## ANOVA: Power Analysis {.smaller}

```{r}
library(dplyr)
library(palmerpenguins)
library(tidyr)
```

:::: {.columns}
::: {.column style="width: 50%; padding-top: 15px;"}
```{r}
adelie <-
  penguins |>
  filter(species == "Adelie") |>
  drop_na() |>
  pull(flipper_length_mm)

adelie |> length()
```

```{r}
chinstrap <-
  penguins |>
  filter(species == "Chinstrap") |>
  drop_na() |>
  pull(flipper_length_mm)

chinstrap |> length()
```
:::
::: {.column style="width: 50%; padding-top: 15px;"}
```{r}
gentoo <-
  penguins |>
  filter(species == "Gentoo") |>
  drop_na() |>
  pull(flipper_length_mm)

gentoo |> length()
```
:::
::::

## ANOVA: Power Analysis {.smaller}

```{r}
library(pwr)
```

```{r}
pwr_analysis <- pwr.anova.test(
  k = 3,
  f = 0.25, # Cohen's f for medium effect sizes
  sig.level = 0.05,
  power = 0.8
)

pwr_analysis
```

::: {.notes}
:::

## ANOVA: Power Analysis {.smaller}

```{r}
#| code-fold: true
#| warning: false
#| fig-align: center

library(pwr)

pwr_analysis |>
  plot.power.htest(
    xlab = "Sample size per group",
    ylab = "Power (1 - Beta)",
    main = NULL
  )
```

::: {.notes}
:::

## ANOVA: Observed Statistic {.smaller}

```{r}
library(dplyr)
library(infer)
library(palmerpenguins)
library(tidyr)
```

```{r}
observed_statistic <-
  penguins |>
  drop_na(flipper_length_mm, species) |>
  specify(flipper_length_mm ~ species) |>
  hypothesize(null = "independence") |>
  calculate(stat = "F")

observed_statistic
```

::: {.notes}
:::

## ANOVA: Null Distribution {.smaller}

```{r}
library(dplyr)
library(infer)
library(palmerpenguins)
library(tidyr)
```

```{r}
null_dist <-
  penguins |>
  drop_na(flipper_length_mm, species) |>
  specify(flipper_length_mm ~ species) |>
  hypothesize(null = "independence") |>
  generate(reps = 1000, type = "permute") |>
  calculate(stat = "F")

null_dist
```

::: {.notes}
:::

## ANOVA: Visualizing {.smaller}

```{r}
#| code-fold: true
#| fig-align: center
#| fig-height: 7
#| fig-width: 15

library(infer)
library(ggplot2)

null_dist |>
  visualize(method = "both") +
  shade_p_value(
    obs_stat = observed_statistic,
    direction = "greater"
  ) +
  labs(
    title = NULL,
    x = "F-statistic",
    y = "Frequency"
  ) +
  theme(text = element_text(size = 14))
```

::: {.notes}
:::

## ANOVA: p-value {.smaller}

```{r}
#| warning: false

null_dist |>
  get_p_value(
    obs_stat = observed_statistic,
    direction = "two-sided"
  )
```

::: {.notes}
:::

## ANOVA: Tukey HSD {.smaller}

Tukey Honest Significant Differences (HSD) test.

```{r}
library(broom)
```

```r
aov(flipper_length_mm ~ species, data = penguins) |>
  TukeyHSD(conf.level = 0.95) |>
  tidy()
```

```{r}
#| echo: false

aov(flipper_length_mm ~ species, data = penguins) |>
  TukeyHSD(conf.level = 0.95) |>
  broom::tidy() |>
  rmarkdown::paged_table()
```

::: {.notes}
:::

## ANOVA: Effect Size {.smaller}

```{r}
library(effectsize)
```

```{r}
#| messages: false
#| warning: false

effect_size <-
  aov(flipper_length_mm ~ species, data = penguins) |>
  cohens_f()

effect_size
```

```{r}
effect_size[[2]] |>
  f_to_eta2() |>
  interpret_eta_squared(rules = "cohen1992")
```

::: {.notes}
:::

## ANOVA: Power Analysis {.smaller}

```{r}
library(pwr)
```

```{r}
pwr.anova.test(
  k = 3,
  n = min(length(adelie), length(chinstrap), length(gentoo)),
  f = effect_size[[2]],
  sig.level = 0.05
)
```

::: {.notes}
:::

## ANOVA: Conclusion {.smaller}

:::: {.columns}
::: {.column style="width: 60%; font-size: 0.8em;"}
[Is there a meaningful difference in flipper length between Adelie, Chinstrap, and Gentoo penguins?]{style="font-size: 1.1em; font-weight: bold; color: #ED6B4D;"}

Our analysis found a statistically significant difference in means ($\text{F}$ = 595, $p$-value < 0.001). The observed effect size was very large and exceed the Minimal Effect Size (MES) threshold ($f$ = 1.873, 95% CI [1.72, Inf]).

The power (1 - $\beta$) of the test is 1, indicating that the probability of a false negative is zero.

Based on these results, we conclude that **there is a meaningful difference in flipper length between Adelie, Chinstrap, and Gentoo penguins**, with Gentoo penguins having significantly longer flippers, followed by Chinstrap penguins. Consequently, we reject the null hypothesis in favor of the alternative hypothesis.
:::
::: {.column style="width: 40%; padding-top: 130px;"}
$$
\begin{cases}
\text{H}_{0}: \mu_{A} = \mu_{B} = \mu_{C} \\
\text{H}_{a}: \mu_{i} \neq \mu_{j}, \ \text{for some} \ i, j
\end{cases}
$$

$$
\begin{cases}
\text{H}_{0}: f < \text{MES} \\
\text{H}_{a}: f \geq \text{MES} \\
\end{cases}
$$
:::
::::

::: {.notes}
:::

## Linear Reg.: Hypothesis {.smaller}

:::: {.columns}
::: {.column style="width: 50%; font-size: 0.85em;"}
[Adding `bill_depth_mm` as a predictor improve the prediction of `flipper_length_mm`?]{style="font-size: 1.1em; font-weight: bold; color: #ED6B4D;"}

To test this, we will use **Nested Linear Models**.

To ensure [practical significance]{style="text-decoration: underline;"}, we will analyze the delta of the adjusted $\text{R}^2$ of the models considering a 95% confidence interval.

We will use Cohen's benchmark for a small effect size as our Minimum Effect Size (MES) [@cohen1988a].
:::
::: {.column style="width: 50%; padding-top: 125px;"}
$$
\begin{cases}
\text{H}_{0}: \Delta \text{Adjusted} \ \text{R}^{2} = 0 \\
\text{H}_{a}: \Delta \text{Adjusted} \ \text{R}^{2} > 0
\end{cases}
$$

$$
\begin{cases}
\text{H}_{0}: \Delta \text{Adjusted} \ \text{R}^{2} < \text{MES} \\
\text{H}_{a}: \Delta \text{Adjusted} \ \text{R}^{2} \geq \text{MES}
\end{cases}
$$
:::
::::

::: {.notes}
:::

## Linear Reg.: Power Analysis {.smaller}

```{r}
library(pwrss)
library(tidyr)
```

```{r}
penguins |>
  drop_na(flipper_length_mm, bill_length_mm, bill_depth_mm) |>
  nrow()
```

```{r}
pwrss.f.reg(
  r2 = 0.02, # Cohen's f^2 for small effect sizes
  k = 2,
  power = 0.8,
  alpha = 0.05
)
```

::: {.notes}
:::

## Linear Reg.: Power Analysis {.smaller}

```{r}
library(pwrss)
library(tidyr)
```

```{r}
penguins |>
  drop_na(flipper_length_mm, bill_length_mm, bill_depth_mm) |>
  nrow()
```

```{r}
pwrss.f.reg(
  r2 = 0.15, # Cohen's f^2 for medium effect sizes
  k = 2,
  power = 0.8,
  alpha = 0.05
)
```

::: {.notes}
:::

## Linear Reg.: Scatterplot 1 {.smaller}

```{r}
#| fig-align: center
#| code-fold: true

library(brandr)
library(ggplot2)
library(palmerpenguins)

penguins |>
  drop_na(bill_length_mm, flipper_length_mm, species) |>
  ggplot(
    aes(
      x = bill_length_mm,
      y = flipper_length_mm,
      color = species,
      shape = species
    )
  ) +
  geom_smooth(
    inherit.aes = FALSE,
    mapping = aes(x = bill_length_mm, y = flipper_length_mm),
    method = "lm",
    formula = y ~ x,
    se = FALSE,
    color = get_brand_color("black")
  ) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE) +
  labs(
    x = "Bill Length (mm)",
    y = "Flipper Length (mm)",
    color = "Species",
    shape = "Species"
  ) +
  scale_color_brand_d(alpha = 0.7)
```

::: {.notes}
:::

## Linear Reg.: Scatterplot 2 {.smaller}

```{r}
#| fig-align: center
#| code-fold: true

library(brandr)
library(ggplot2)
library(palmerpenguins)
library(tidyr)

penguins |>
  drop_na(bill_depth_mm, flipper_length_mm, species) |>
  ggplot(
    aes(
      x = bill_depth_mm,
      y = flipper_length_mm,
      color = species,
      shape = species
    )
  ) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE) +
  geom_smooth(
    inherit.aes = FALSE,
    mapping = aes(x = bill_depth_mm, y = flipper_length_mm),
    method = "lm",
    formula = y ~ x,
    se = FALSE,
    color = get_brand_color("black")
  ) +
  labs(
    x = "Bill Depth (mm)",
    y = "Flipper Length (mm)",
    color = "Species",
    shape = "Species"
  ) +
  scale_color_brand_d(alpha = 0.7)
```

::: {.notes}
:::

## Linear Reg.: Prediction {.smaller}

```{r}
#| code-fold: true
#| fig-align: center

library(brandr)
library(broom)
library(ggplot2)
library(palmerpenguins)
# library(rutils) # github.com/danielvartan/rutils
library(tidyr)

data <- penguins |> drop_na(flipper_length_mm, bill_length_mm, bill_depth_mm)

fit <-
  formula(flipper_length_mm ~ bill_length_mm + bill_depth_mm) |>
  lm(data)

fit |>
  augment(data) |>
  ggplot(aes(x = bill_length_mm, y = flipper_length_mm)) +
  geom_point() +
  geom_line(
    aes(y = .fitted, color = "Prediction"),
    linewidth = 0.5,
    alpha = 0.5,
  ) +
  geom_function(
    aes(color = "Adjusted prediction"),
    fun = rutils:::lm_fun(fit, fix_all_but = 1, data = data),
    linewidth = 1
  ) +
  labs(
    x = "Bill depth (mm)",
    y = "Flipper length (mm)",
    subtitle = rutils:::lm_str_fun(fit, fix_all_but = 1),
    color = NULL
  ) +
  ggplot2::scale_color_manual(
    values = c(
      "Prediction" = get_brand_color("green"),
      "Adjusted prediction" = get_brand_color("red")
    )
  )
```

## Linear Reg.: Plane {.smaller}

```{r}
#| eval: false
#| include: false

# Source: https://stackoverflow.com/a/70979149/8258804

# To find the `theta` and `phi` angles, do the following:
#
# * Install the `orientlib` package before doing this.
#
# 1. Run the chunk below to get a viewport open.
# 2. Adjust the size of the viewport to the size of the Quarto chart rendering.
# 3. Run `user_matrix <- rgl::par3d()$userMatrix` to get the user matrix.
# 4. Run `zoom <- rgl::par3d()$zoom` to get the zoom.
# 5. Add `user_matrix` and `zoom` to the `rgl::view3d()` function.

# install.packages("orientlib")
# user_matrix <- rgl::par3d()$userMatrix
# zoom <- rgl::par3d()$zoom
```

```{r}
#| code-fold: true

library(dplyr)
library(palmerpenguins)
library(predict3d)
library(rgl)
library(tidyr)

user_matrix <-
  dplyr::tribble(
    ~a,         ~b,         ~c,          ~d,
    0.6233152,  -0.7817951, -0.01657271, 0,
    0.1739255,  0.1179437,  0.97767037,  0,
    -0.7623830, -0.6122792, 0.20949011,  0,
    0,          0,          0,           1
  ) |>
  as.matrix() |>
  `colnames<-`(NULL)

data <- penguins |> drop_na(flipper_length_mm, bill_length_mm, bill_depth_mm)

formula(flipper_length_mm ~ bill_length_mm + bill_depth_mm) |>
  lm(data) |>
  predict3d(
    xlab = "Bill length (mm)",
    ylab = "Bill depth (mm)",
    zlab = "Flipper length (mm)",
    radius = 0.75,
    type = "s",
    color = "red",
    show.subtitle = FALSE,
    show.error = FALSE
  )

view3d(userMatrix = user_matrix, zoom = 0.9)

rglwidget(elementId = "1st") |>
  suppressMessages() |>
  suppressWarnings()
```

::: {.notes}
In a multiple linear regression with two predictors, the model is fit by adjusting a **plane** to the data points (**Use the mouse to explore**).
:::

## Linear Reg.: Fit (Restricted) {.smaller}

:::: {.columns}
::: {.column style="width: 50%;"}
```{r}
library(broom)
library(palmerpenguins)
library(parsnip)
```

```{r}
model <-
  linear_reg() |>
  set_engine("lm")
```

```{r}
fit_restricted <-
  model |>
  fit(flipper_length_mm ~ bill_length_mm, data = penguins)
```

```{r}
fit_restricted |> tidy() |> adorn_rounding(5)
```
:::
::: {.column style="width: 50%;"}
```{r}
fit_restricted_stats <- fit_restricted |> glance()
```

```{r}
fit_restricted_stats |>
  tidyr::pivot_longer(cols = dplyr::everything()) |>
  adorn_rounding(5)
```
:::
::::

::: {.notes}
:::

## Linear Reg.: Fit (Full) {.smaller}

:::: {.columns}
::: {.column style="width: 50%;"}
```{r}
library(broom)
library(palmerpenguins)
library(parsnip)
```

```{r}
model <-
  linear_reg() |>
  set_engine("lm")
```

```{r}
fit_full <-
  model |>
  fit(flipper_length_mm ~ bill_length_mm + bill_depth_mm, data = penguins)
```

```{r}
fit_full |> tidy() |> adorn_rounding(5)
```
:::
::: {.column style="width: 50%;"}
```{r}
fit_full_stats <- fit_full |> glance()
```

```{r}
fit_full_stats |>
  tidyr::pivot_longer(cols = dplyr::everything()) |>
  adorn_rounding(5)
```
:::
::::

::: {.notes}
:::

## Linear Reg.: ANOVA {.smaller}

```{r}
library(broom)
library(janitor)
```

```r
anova(fit_restricted$fit, fit_full$fit) |>
  tidy() |>
  adorn_rounding(5)
```

```{r}
#| echo: false

anova(fit_restricted$fit, fit_full$fit) |>
  broom::tidy() |>
  adorn_rounding(5) |>
  rmarkdown::paged_table()
```

::: {.notes}
:::

## Linear Reg.: Effect Size {.smaller}

```{r}
library(effectsize)
library(psychometric)
```

```{r}
fit_restricted_stats$adj.r.squared
```

```{r}
fit_restricted_stats$adj.r.squared |> interpret_r2(rules = "cohen1988")
```

```{r}
fit_full_stats$adj.r.squared
```

```{r}
fit_full_stats$adj.r.squared |> interpret_r2(rules = "cohen1988")
```

```{r}
delta <- fit_full_stats$adj.r.squared - fit_restricted_stats$adj.r.squared

delta
```

::: {.notes}
:::

## Linear Reg.: Effect Size {.smaller}

```{r}
CI.Rsq(
  rsq = delta,
  n = penguins |> nrow(),
  k = 2
)
```

```{r}
delta |> interpret_r2(rules = "cohen1988")
```

::: {.notes}
:::

## Linear Reg.: Power Analysis {.smaller}

```{r}
library(pwrss)
library(tidyr)
```

```{r}
pwrss.f.reg(
  r2 = fit_full_stats$adj.r.squared,
  k = 2,
  n =
    penguins |>
    drop_na(flipper_length_mm, bill_length_mm, bill_depth_mm) |>
    nrow(),
  power = NULL,
  alpha = 0.05
)
```

::: {.notes}
:::

## Linear Reg.: Conclusion {.smaller}

:::: {.columns}
::: {.column style="width: 60%; font-size: 0.8em;"}
[Adding `bill_depth_mm` as a predictor meaningful improve the prediction of `flipper_length_mm`?]{style="font-size: 1.1em; font-weight: bold; color: #ED6B4D;"}

Our analysis indicates that adding `bill_depth_mm` as a predictor improves the model adjusted $\text{R}^{2}$ in 0.19483 (95% CI \[0.12069, 0.26897\]) ($\text{F}$(2, 339) = 284, $p$-value < 0.001), exceeding the Minimal Effect Size (MES) threshold.

The power (1 - $\beta$) of the test is 1, indicating that the probability of a false negative is zero.

Based on these results, we conclude that **`bill_depth_mm` meaningful improve the prediction of `flipper_length_mm`**. Consequently, we reject the null hypothesis in favor of the alternative hypothesis.
:::
::: {.column style="width: 40%; padding-top: 130px;"}
$$
\begin{cases}
\text{H}_{0}: \Delta \text{Adjusted} \ \text{R}^{2} = 0 \\
\text{H}_{a}: \Delta \text{Adjusted} \ \text{R}^{2} > 0
\end{cases}
$$

$$
\begin{cases}
\text{H}_{0}: \Delta \text{Adjusted} \ \text{R}^{2} < \text{MES} \\
\text{H}_{a}: \Delta \text{Adjusted} \ \text{R}^{2} \geq \text{MES}
\end{cases}
$$
:::
::::

::: {.notes}
:::

## Model Diagnostics {.smaller}

:::: {.columns}
::: {.column style="width: 47.5%;"}
**Model diagnostics are crucial!**

It's essential to verify that all model assumptions hold. However, a discussion on this topic is beyond the scope of this course.

You can find these assumptions in most statistical textbooks, or you can look at the original papers that introduced the models (e.g., fot t-Tests, see @student1908).
:::
::: {.column style="width: 5%;"}
:::
::: {.column style="width: 47.5%;"}
![](images/allison-horst-figure-38.png){fig-align="center" style="width: 90%; padding-top: 100px;"}
:::
::::

::: footer
(Artwork by [Allison Horst](https://twitter.com/allison_horst))
:::

::: {.notes}
:::

## Objective Assumption Tests {.smaller}

🚨 **Avoid Using!** 🚨

Objective assumption tests (e.g., Anderson–Darling test) are not advisable for large samples, as they can be overly sensitive to minor deviations. Additionally, they might overlook visual patterns that are not captured by a single metric.

Usually, a visual inspection of the data is the preferred approach in most cases.

For a straightforward critique of normality tests specifically, refer to [this](https://towardsdatascience.com/stop-testing-for-normality-dba96bb73f90) article by @greener2020.

See also: @kozak2018, @schucany2006, and @shatz2024.

::: {.notes}
:::

## How to Learn More {.smaller}

:::: {.columns}
::: {.column style="width: 47.5%;"}
[![](images/degroot-2012-book-cover.jpg){fig-align="center" style="width: 85%;"}](https://books.google.com.br/books/about/Probability_and_Statistics.html?id=4TlEPgAACAAJ&redir_esc=y)
:::
::: {.column style="width: 5%;"}
:::
::: {.column style="width: 47.5%;"}
[![](images/kuhn-2022-book-cover.jpg){fig-align="center" style="width: 83%;"}](https://www.tmwr.org/)
:::
::::

::: footer
(Book cover image from @degroot2012a and @kuhn2022)
:::

::: {.notes}
:::

## How to Learn More {.smaller}

:::: {.columns}
::: {.column style="width: 50%; text-align: center; padding-top: 50px;"}
[![](images/statquest-logo.jpg){fig-align="center" style="width: 50%; border-radius:50%; border:1px solid black;"}](https://www.youtube.com/c/joshstarmer)

**StatQuest**`<br>`{=html}by Josh Starmer
:::
::: {.column style="width: 50%; text-align: center; padding-top: 50px;"}
[![](images/very-normal-logo.png){fig-align="center" style="width: 50%; border-radius:50%; border:1px solid black;"}](https://www.youtube.com/@very-normal)

**Very Normal**`<br>`{=html}by Christian Pascual
:::
::::

::: {.notes}
:::
