## Modeling with Tidyverse *versus* Modeling with base R {.smaller}

The [tidyverse](https://www.tidyverse.org/) framework offers a structured and consistent approach to modeling in R through the [tidymodels](https://www.tidymodels.org/) ecosystem.

While many users still utilize base R functions for modeling, we will focus on the tidyverse approach due to its simplicity and readability.

::: {.notes}
:::

## The Tidymodels Framework {.smaller}

[![](images/tidymodels-hex-logo.png){style="width: 120px;"}](https://www.tidymodels.org/)

The `tidymodels` framework is a collection of packages for modeling and machine learning using [tidyverse](https://www.tidyverse.org/) principles.

::: {.notes}
:::

## Power Analysis (.smaller)

::: {style="font-size: 0.7em; padding-top: 75px;"}
| **Decision about** $H_{0}$ | $H_{0}$ **True**                                               | $H_{0}$ **False**                                                |
|------------------------------|-----------------------------------------------------------------|--------------------------------------------------------------------|
| **Accept**               | Correct inference (true negative) ($\text{prob} = 1 - \alpha$) | Type II error (False negative) ($\text{prob} = \beta$)           |
| **Reject**                   | Type I error (False positive) ($\text{prob} = \alpha$)         | Correct inference (true positive) ($\text{prob} = 1 - \beta$)    |
:::

::: footer
(Based on @@casella2002[p. 383])
:::

::: {.notes}
:::

## Power Analysis {.smaller .nostretch}

![](images/type-1-and-type-2-errors-chart.webp){fig-align="center" style="width: 80%; padding-top: 15px;"}

::: footer
(Artwork by [VWO](https://vwo.com/blog/errors-in-ab-testing/))
:::

::: {.notes}
:::

## Type I Errors ($\alpha$) {.smaller}

![](images/allison-horst-figure-39.png){fig-align="center" style="width: 90%; padding-top: 30px;"}

::: footer
(Artwork by [Allison Horst](https://twitter.com/allison_horst))
:::

::: {.notes}
:::

## Type II Errors ($\beta$) {.smaller}

![](images/allison-horst-figure-40.png){fig-align="center" style="width: 90%; padding-top: 30px;"}

::: footer
(Artwork by [Allison Horst](https://twitter.com/allison_horst))
:::

::: {.notes}
:::

## The *p*-value Problem {.smaller}

::::: {.columns}
:::: {.column style="width: 40%; padding-top: 0px;"}
Large samples and sensitivity

Is a difference of $0.00001$ valid?

Statistical ritual *versus* Statistical thinking

::: {style="font-size: 0.5em; font-style: italic; padding-top: 15px;"}
Comparison of a 95% of confidence level ($\alpha = 0.05$) and an *n*-dependent *p-value* curve. The parameter $n_{\alpha}$ represents the minimum sample size to detect statistically significant differences among compared groups. The parameter $n_{\gamma}$ represents the convergence point of the *p-value* curve. When the *p-value* curve expresses practical differences, the area under the red curve ($A_{p(n)}$) is smaller than the area under the constant function $\alpha = 0.05$ ($A_{\alpha = 0.05}$) when it is evaluated between $0$ and $n_{\gamma}$.
:::
::::
:::: {.column style="width: 60%; padding-top: 100px;"}
![](images/gomez-de-mariscal-2021-figure-3.png){fig-align="center" style="width: 75%; padding-top: 0px;"}
::::
:::::

::: footer
(Reproduced from @mariscal2021[Figure 3])
:::

::: {.notes}
:::

## Cohen's Benchmark {.smaller}

:::: {.columns}
::: {.column style="width: 50%;"}
> [...] in many circumstances, all that is intended by "proving" the null hypothesis is that the ES [Effect Size] is not necessarily zero but **small enough to be negligible** [...] [@cohen1988a[p. 461]].
:::
::: {.column style="width: 50%;"}
![](images/jacob-cohen-figure-1.jpg){fig-align="center" style="width: 80%; padding-top: 25px;"}
:::
::::

::: footer
(Photo by an unknown author.)
:::

::: {.notes}
:::

## Cohen's Benchmark {.smaller}

![](images/cohen-1992-table-1.png){fig-align="center" style="padding-top: 10px; padding-bottom: 25px;"}

::: footer
(Reproduced from @cohen1992)
:::

::: {.notes}
:::

## One-Sample t-Test: Hypothesis {.smaller}

To ensure practical significance, the difference in means must be analyzed for its effect size considering a 95% confidence interval.

We will use Cohen's benchmark for a small effect size as our Minimum Effect Size (MES) (@cohen1988a).

$$
\begin{cases}
\text{H}_{0}: \mu_{A} = \mu_{B} \\
\text{H}_{a}: \mu_{A} \neq \mu_{B} \\
\end{cases}
$$


$$
\begin{cases}
\text{H}_{0}: \mu_{A} - \mu_{B} <= \text{MES} \\
\text{H}_{a}: \mu_{A} - \mu_{B} > \text{MES} \\
\end{cases}
$$

::: {.notes}
:::

## One-Sample t-Test: Hypothesis {.smaller}

```{r}
#| fig-align: center
#| code-fold: true
#| warning: false

library(brandr)
library(ggplot2)
library(palmerpenguins)
library(tidyr)

penguins |>
  filter(species %in% c("Adelie", "Gentoo")) |>
  drop_na(flipper_length_mm, species) |>
  ggplot(aes(x = species, y = flipper_length_mm, fill = species)) +
  geom_boxplot(outlier.color = brandr::get_brand_color("dark-red")) +
  geom_jitter(width = 0.2, alpha = 0.1) +
  scale_fill_brand_d(alpha = 0.7) +
  labs(x = "Species", y = "Flipper Length (mm)", fill = "Species")
```

::: {.notes}
:::

## One-Sample t-Test: P. Analysis {.smaller}

```{r}
library(pwrss)
```

```{r}
library(pwrss)

pwrss.t.2means(
  mu1 = 0.2, # Cohen's d for small effect size
  mu2 = 0,
  power = 0.8,
  alpha = 0.05,
  welch.df = TRUE,
  alternative = "not equal"
)
```

::: {.notes}
:::

## One-Sample t-Test: P. Analysis {.smaller}

```{r}
library(pwrss)
```

```{r}
pwrss.t.2means(
  mu1 = 0.5, # Cohen's d for medium effect size
  mu2 = 0,
  power = 0.8,
  alpha = 0.05,
  welch.df = TRUE,
  alternative = "not equal"
)
```

::: {.notes}
:::

## One-Sample t-Test: Observed Statistic {.smaller}

```{r}
library(dplyr)
library(infer)
library(palmerpenguins)
library(tidyr)
```

```{r}
observed_statistic <-
  penguins |>
  filter(species %in% c("Adelie", "Gentoo")) |>
  drop_na(flipper_length_mm, species) |>
  specify(flipper_length_mm ~ species) |>
  hypothesize(null = "independence") |>
  calculate("t", order = c("Adelie", "Gentoo"))

observed_statistic
```

::: {.notes}
:::

## One-Sample t-Test: N. Dist. {.smaller}

```{r}
library(dplyr)
library(infer)
library(palmerpenguins)
library(tidyr)
```

```{r}
null_dist <-
  penguins |>
  filter(species %in% c("Adelie", "Gentoo")) |>
  drop_na(flipper_length_mm, species) |>
  specify(flipper_length_mm ~ species) |>
  hypothesize(null = "independence") |>
  generate(reps = 1000, type = "permute") |>
  calculate("t", order = c("Adelie", "Gentoo"))

null_dist
```

::: {.notes}
:::

## One-Sample t-Test: Visualizing {.smaller}

```{r}
#| fig-align: center
#| fig-height: 5
#| fig-width: 15

null_dist |>
  visualize() +
  shade_p_value(obs_stat = observed_statistic, direction = "two-sided") +
  ggplot2::labs(
    title = NULL,
    x = "t-statistic",
    y = "Frequency"
  ) +
  theme(text = element_text(size = 14))
```

::: {.notes}
:::

## One-Sample t-Test: p-value {.smaller}

```{r}
null_dist |>
  get_p_value(obs_stat = observed_statistic, direction = "two-sided")
```

::: {.notes}
:::

## One-Sample t-Test: Power Analysis {.smaller}

```{r}
library(dplyr)
library(palmerpenguins)
library(tidyr)
```

```{r}
adelie <-
  penguins |>
  dplyr::filter(species == "Adelie") |>
  tidyr::drop_na() |>
  dplyr::pull(flipper_length_mm)

gentoo <-
  penguins |>
  dplyr::filter(species == "Gentoo") |>
  tidyr::drop_na() |>
  dplyr::pull(flipper_length_mm)
```

## One-Sample t-Test: Effect Size {.smaller}

```{r}
library(effectsize)
```

```{r}
effect_size <-
  cohens_d(
    x = adelie,
    y = gentoo,
    mu = 0,
    adjust = TRUE, # Hedge's g
    ci = 0.95,
    alternative = "two.sided"
  )

effect_size
```

```{r}
effect_size |> interpret_hedges_g(rules = "cohen1988")
```

::: {.notes}
:::

## One-Sample t-Test: P. Analysis {.smaller}

```{r}
library(pwrss)
```

```{r}
#| warning: false

pwrss.t.2means(
  mu1 = adelie |> mean(na.rm = TRUE),
  mu2 = gentoo |> mean(na.rm = TRUE),
  sd1 = adelie |> sd(na.rm = TRUE),
  sd2 = gentoo |> sd(na.rm = TRUE),
  paired = FALSE,
  n2 = gentoo |> length(),
  kappa = (adelie |> length()) / (gentoo |> length()),
  power = NULL,
  alpha = 0.05,
  welch.df = TRUE,
  alternative = "not equal"
)
```

::: {.notes}
:::

## One-Way ANOVA: Hypothesis {.smaller}

To ensure practical significance, the difference in means must be analyzed for its effect size considering a 95% confidence interval.

We will use Cohen's benchmark for a small effect size as our Minimum Effect Size (MES) (@cohen1988a).

$$
\begin{cases}
\text{H}_{0}: \mu_{A} = \mu_{B} = \mu_{C} \\
\text{H}_{a}: \mu_{i} \neq \mu_{j}, \ \text{for some} \ i, j
\end{cases}
$$

::: {.notes}
:::

## One-Way ANOVA: Boxplots {.smaller}

```{r}
#| fig-align: center
#| code-fold: true
#| warning: false

library(brandr)
library(ggplot2)
library(palmerpenguins)
library(tidyr)

penguins |>
  drop_na(flipper_length_mm, species) |>
  ggplot(aes(x = species, y = flipper_length_mm, fill = species)) +
  geom_boxplot(outlier.color = get_brand_color("dark-red")) +
  geom_jitter(width = 0.2, alpha = 0.1) +
  scale_fill_brand_d(alpha = 0.7) +
  labs(x = "Species", y = "Flipper Length (mm)", fill = "Species")
```

::: {.notes}
:::

## One-Way ANOVA: Fit (Base R) {.smaller}

```{r}
fit <- aov(flipper_length_mm ~ species, data = penguins)

fit
```

::: {.notes}
:::

## One-Way ANOVA: Fit Summary (Base R) {.smaller}

```{r}
fit |> summary()
```

## One-Way ANOVA: Tukey HSD (Base R) {.smaller}

```{r}
 fit |> TukeyHSD()
```

::: {.notes}
:::

## One-Way ANOVA: Effect Size {.smaller}

```{r}
library(effectsize)
```

```{r}
effect_size <- fit |> eta_squared()

effect_size
```

```{r}
effect_size |> interpret_eta_squared(rules = "cohen1992")
```

::: {.notes}
:::

## One-Way ANOVA: Power Analysis {.smaller}

```{r}
library(pwrss)

pwrss.f.ancova(
  eta2 = effect_size$Eta2,
  n.way = 1,
  n.levels = 3,
  n.covariates = 0,
  alpha = 0.05,
  n = penguins |> nrow(),
  power = NULL
)
```

::: {.notes}
:::

## Linear Regression: Hypothesis {.smaller}

To ensure practical significance, the adjusted $\text{R}^2$ of the model must be analyzed for its effect size considering a 95% confidence interval.

We will use Cohen's benchmark for a small effect size as our Minimum Effect Size (MES) (@cohen1988a).

$$
\begin{cases}
\text{H}_{0}: \text{Adjusted} \ \text{R}^{2} \leq \text{MES} \quad \text{or} \quad \text{F-test is not significant} \ (\alpha \geq 0.05) \\
\text{H}_{a}: \text{Adjusted} \ \text{R}^{2} > \text{MES} \quad \text{and} \quad \text{F-test is significant} \ (\alpha < 0.05)
\end{cases}
$$

::: {.notes}
:::

## Linear Regression: Scatterplot 1 {.smaller}

```{r}
#| fig-align: center
#| code-fold: true

library(brandr)
library(ggplot2)
library(palmerpenguins)

penguins |>
  drop_na(flipper_length_mm, body_mass_g, species) |>
  ggplot(
    aes(
      x = flipper_length_mm,
      y = bill_length_mm,
      color = species,
      shape = species
    )
  ) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE) +
  labs(
    x = "Flipper Length (mm)",
    y = "Bill Length (mm)",
    color = "Species",
    shape = "Species"
  ) +
  brandr::scale_color_brand_d(alpha = 0.7)
```

::: {.notes}
:::

## Linear Regression: Scatterplot 2 {.smaller}

```{r}
#| fig-align: center
#| code-fold: true

library(brandr)
library(ggplot2)
library(palmerpenguins)
library(tidyr)

penguins |>
  drop_na(flipper_length_mm, body_mass_g, species) |>
  ggplot(
    aes(
      x = flipper_length_mm,
      y = bill_depth_mm,
      color = species,
      shape = species
    )
  ) +
  geom_point(size = 2) +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE) +
  labs(
    x = "Flipper Length (mm)",
    y = "Bill Depth (mm)",
    color = "Species",
    shape = "Species"
  ) +
  brandr::scale_color_brand_d(alpha = 0.7)
```

::: {.notes}
:::

## Linear Regression: Fit (Base R) {.smaller}

```{r}
fit <- lm(
  formula = flipper_length_mm ~ bill_length_mm + bill_depth_mm,
  data = penguins
)

fit
```

::: {.notes}
:::

## Linear Regression: Fit Summary (Base R) {.smaller}

```{r}
fit_sum <- fit |> summary()

fit_sum
```

::: {.notes}
:::

## Linear Regression: Effect Size {.smaller}

$$
\text{Cohen's } f^2 = \cfrac{\text{R}^{2}}{1 - \text{R}^{2}}
$$

$$
\text{Cohen's } f^2 \text{small threshold} = 0.02
$$

$$
0.02 = \cfrac{\text{R}^{2}}{1 - \text{R}^{2}} \quad \text{or} \quad \text{R}^{2} = \cfrac{0.02}{1.02} \eqsim 0.01960784
$$

## Linear Regression: Effect Size {.smaller}

```{r}
library(effectsize)
```

```{r}
fit_sum$r.squared |> interpret_r2(rules = "cohen1988")
```

::: {.notes}
:::

## Linear Regression: Power Analysis {.smaller}

```{r}
library(pwrss)
```

```{r}
pwrss.f.reg(
  r2 = fit_sum$r.squared,
  k = 2,
  n = penguins |> nrow(),
  power = NULL,
  alpha = 0.05
)
```

::: {.notes}
:::

## Model Diagnostics {.smaller}

:::: {.columns}
::: {.column style="width: 47.5%;"}
**Model diagnostics are crucial!**

It's essential to verify that all model assumptions hold. However, a detailed discussion on this topic is beyond the scope of this course.

You can find these assumptions in most statistical textbooks, or you can look at the original papers that introduced the models (e.g., fot t-Tests, see @student1908).
:::
::: {.column style="width: 5%;"}
:::
::: {.column style="width: 47.5%;"}
![](images/allison-horst-figure-38.png){fig-align="center" style="width: 90%; padding-top: 100px;"}
:::
::::

::: footer
(Artwork by [Allison Horst](https://twitter.com/allison_horst))
:::

::: {.notes}
:::

## Objective Assumption Tests {.smaller}

ðŸš¨ **Avoid Using!**

Objective assumption tests (e.g., Andersonâ€“Darling test) are not advisable for large samples, as they can be overly sensitive to minor deviations. Additionally, they might overlook visual patterns that are not captured by a single metric.

Usually, a visual inspection of the data is the preferred approach in most cases.

For a straightforward critique of normality tests specifically, refer to [this](https://towardsdatascience.com/stop-testing-for-normality-dba96bb73f90) article by @greener2020.

See also: @kozak2018, @schucany2006, and @shatz2024.

::: {.notes}
:::

## How to Learn More {.smaller}

:::: {.columns}
::: {.column style="width: 47.5%;"}
[![](images/degroot-2012-book-cover.jpg){fig-align="center" style="width: 85%;"}](https://books.google.com.br/books/about/Probability_and_Statistics.html?id=4TlEPgAACAAJ&redir_esc=y)
:::
::: {.column style="width: 5%;"}
:::
::: {.column style="width: 47.5%;"}
[![](images/kuhn-2022-book-cover.jpg){fig-align="center" style="width: 83%;"}](https://www.tmwr.org/)
:::
::::

::: footer
(Book cover image from @degroot2012a and @kuhn2022)
:::

::: {.notes}
:::
