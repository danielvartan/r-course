```{r}
#| include: false
#| label: module-5-first-chunk
```

## The Tidymodels Framework {.smaller}

[![](images/tidymodels-hex-logo.png){style="width: 120px;"}](https://www.tidymodels.org/)

The [Tidymodels](https://www.tidymodels.org/) framework is a collection of packages for modeling and machine learning using [Tidyverse](https://www.tidyverse.org/) principles.

It is created by the same team that developed the `tidyverse` and is designed to work seamlessly with it.

Although it is a relative newcomer to the R ecosystem (2018), it has quickly gained popularity due to its simplicity and consistency.

::: {.notes}
- Talk about the purpose of this module. It is not intend to teach statistics. Students with no statistical background may find it difficult to follow.
:::

## Tidymodels Packages {.smaller}

Like Tidyverse, Tidymodels also has a meta-package that installs or load the most important packages from the collection.

:::: {.columns}
::: {.column style="width: 50%; padding-top: 10px; padding-bottom: 10px;"}
```r
install.packages("tidymodels")
```
:::
::: {.column style="width: 50%; padding-top: 10px; padding-bottom: 10px;"}
```r
library("tidymodels")
```
:::
::::

::: {style="font-size: 1em; padding-top: 15px;"}
- [`rsample`](https://rsample.tidymodels.org): Provides infrastructure for efficient data splitting and resampling.
- [`parsnip`](https://parsnip.tidymodels.org): A tidy, unified interface to models.
- [`recipes`](https://recipes.tidymodels.org): A tidy interface to data pre-processing tools for feature engineering.
- [`workflows`](https://workflows.tidymodels.org): A package to bundle the pre-processing, modeling, and post-processing together.
- [`infer`](https://infer.tidymodels.org): A statistical **grammar** for inferential statistics.
:::

::: {.notes}
:::

## Hypothesis Testing {.smaller}

A [hypothesis]{.brand-triad-blue-red .bold-black} is a statement about a population parameter.

::: {style="padding-top: 15px;"}
The goal of a hypothesis test is to decide, based on a sample from the population, which of **two complementary hypotheses** is true.

The two complementary hypotheses in a hypothesis testing problem are called the **null hypothesis** and the **alternative hypothesis**. They are denoted by $\text{H}_{0}$ and $\text{H}_{1}$, respectively.
:::

::: {style="padding-top: 15px;"}
A hypothesis testing procedure or [hypothesis test]{.brand-triad-blue-red .bold-black} is a rule that specifies:

1. For which sample values the decision is made to accept $\text{H}_{0}$ as true.
1. For which sample values $\text{H}_{0}$ is rejected and $\text{H}_{1}$, is accepted as true.
:::

::: footer
[@casella2002, p. 373-374]
:::

::: {.notes}
:::

## Power Analysis {.smaller}

::: {style="padding-top: 100px;"}
```{r}
#| echo: false

library(dplyr)
library(gt)
library(katex)

tibble(
  decision = c("Accept", "Reject"),
  h0_true = c(
    "Correct inference<br>(True negative)<br>($1 - \\alpha$)",
    "Type I error<br>(False positive)<br>($\\alpha$)"
  ),
  h0_false = c(
    "Type II error<br>(False negative)<br>($\\beta$)",
    "Correct inference<br>(True positive)<br>($1 - \\beta$)"
  )
) |>
  gt() |>
  tab_options(
    table.width = pct(70),
    table.font.size = pct(80)
  ) |>
  cols_label(
    decision = md("Decision about $\\text{H}_{0}$"),
    h0_true = md("$\\text{H}_{0}$ True"),
    h0_false = md("$\\text{H}_{0}$ False")
  ) |>
  cols_align(
    align = "center",
    columns = c(decision, h0_true, h0_false)
  ) |>
  # cols_width(
  #   starts_with("decision") ~ px(200),
  #   everything() ~ px(300)
  # ) |>
  tab_options(column_labels.font.weight = "bold") |>
  fmt_markdown(columns = everything()) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_body(
      columns = decision,
      rows = everything()
    )
  ) |>
  tab_style(
    style = cell_text(align = "center"),
    locations = cells_body(columns = c(decision, h0_true, h0_false))
  ) |>
  data_color(
    columns = "h0_true",
    rows = 1,
    palette = brandr::get_brand_color_tint(900, "square-blue-green")
  )  |>
  data_color(
    columns = "h0_true",
    rows = 2,
    palette = brandr::get_brand_color_tint(900, "triad-blue-red")
  )  |>
  data_color(
    columns = "h0_false",
    rows = 1,
    palette = brandr::get_brand_color_tint(900, "triad-blue-red")
  )  |>
  data_color(
    columns = "h0_false",
    rows = 2,
    palette = brandr::get_brand_color_tint(900, "square-blue-green")
  )
```
:::

::: footer
(Based on @casella2002[p. 383])
:::

::: {.notes}
:::

## Power Analysis {.smaller .nostretch}

```{r}
#| code-fold: true
#| warning: false
#| fig-align: center

library(pwrss)

pwr_analysis <- pwrss.t.2means(
  mu1 = 0.2, # Cohen's d for small effect sizes
  mu2 = 0,
  power = 0.8,
  alpha = 0.05,
  welch.df = TRUE,
  alternative = "greater"
)

power.t.test(
  ncp = pwr_analysis$ncp,
  df = pwr_analysis$df,
  alpha = pwr_analysis$parms$alpha,
  alternative = "one.sided",
  plot = TRUE,
  verbose = FALSE
)
```

::: {.notes}
:::

## Power Analysis {.smaller .nostretch}

```{r}
#| code-fold: true
#| warning: false
#| fig-align: center

library(pwrss)

pwr_analysis <- pwrss.t.2means(
  mu1 = 0.2, # Cohen's d for small effect sizes
  mu2 = 0,
  power = 0.3,
  alpha = 0.05,
  welch.df = TRUE,
  alternative = "greater",
)

power.t.test(
  ncp = pwr_analysis$ncp,
  df = pwr_analysis$df,
  alpha = pwr_analysis$parms$alpha,
  alternative = "one.sided",
  plot = TRUE,
  verbose = FALSE
)
```

::: {.notes}
:::

## Power Analysis {.smaller .nostretch}

```{r}
#| code-fold: true
#| warning: false
#| fig-align: center

library(pwrss)

pwr_analysis <- pwrss.t.2means(
  mu1 = 0.2, # Cohen's d for small effect sizes
  mu2 = 0,
  power = 0.999,
  alpha = 0.001,
  welch.df = TRUE,
  alternative = "greater",
)

power.t.test(
  ncp = pwr_analysis$ncp,
  df = pwr_analysis$df,
  alpha = pwr_analysis$parms$alpha,
  alternative = "one.sided",
  plot = TRUE,
  verbose = FALSE
)
```

::: {.notes}
:::

## Type I Errors ($\alpha$) {.smaller data-menu-title="Type I Errors"}

![](images/allison-horst-figure-39.png){.nostretch fig-align="center" style="width: 90%; padding-top: 0px;"}

::: footer
(Artwork by [Allison Horst](https://twitter.com/allison_horst))
:::

::: {.notes}
:::

## Type II Errors ($\beta$) {.smaller data-menu-title="Type II Errors"}

![](images/allison-horst-figure-40.png){.nostretch fig-align="center" style="width: 100%; padding-top: 30px;"}

::: footer
(Artwork by [Allison Horst](https://twitter.com/allison_horst))
:::

::: {.notes}
:::

## The *p*-value Problem {.smaller}

::::: {.columns}
:::: {.column style="width: 40%; padding-top: 0px;"}
Large samples and sensitivity

Is a difference of $0.00001$ valid?

Statistical ritual *versus* Statistical thinking

::: {style="font-size: 0.5em; font-style: italic; padding-top: 15px;"}
Comparison of a 95% of confidence level ($\alpha = 0.05$) and an *n*-dependent *p-value* curve. The parameter $n_{\alpha}$ represents the minimum sample size to detect statistically significant differences among compared groups. The parameter $n_{\gamma}$ represents the convergence point of the *p-value* curve. When the *p-value* curve expresses practical differences, the area under the red curve ($A_{p(n)}$) is smaller than the area under the constant function $\alpha = 0.05$ ($A_{\alpha = 0.05}$) when it is evaluated between $0$ and $n_{\gamma}$.
:::
::::
:::: {.column style="width: 60%; padding-top: 100px;"}
![](images/gomez-de-mariscal-2021-figure-3.png){fig-align="center" style="width: 75%; padding-top: 0px;"}
::::
:::::

::: footer
(Reproduced from @mariscal2021[Figure 3])
:::

::: {.notes}
:::

## Cohen's Benchmark {.smaller}

:::: {.columns}
::: {.column style="width: 50%;"}
> [...] in many circumstances, all that is intended by "proving" the null hypothesis is that the ES [Effect Size] is not necessarily zero but **small enough to be negligible**`<br>`{=html}[@cohen1988a, p. 461].
:::
::: {.column style="width: 50%;"}
![](images/jacob-cohen-figure-1.jpg){fig-align="center" style="width: 80%; padding-top: 25px;"}
:::
::::

::: footer
(Photo by an unknown author.)
:::

::: {.notes}
:::

## Cohen's Benchmark {.smaller}

```{r}
#| echo: false

library(dplyr)
library(gt)

tibble(
  test = c(
    "Comparison of independent means", "Comparison of two correlations",
    "Difference between proportions", "Correlation", "", "Crosstabulation",
    "ANOVA", "", "Multiple regression", ""
  ),
  relevant_effect_size = c(
    "$d$, $\\Delta$, Hedges‚Äô $g$", "$q$", "Cohen‚Äôs $g$", "$r$", "$r^{2}$",
    "$w$, $\\varphi$, $V$, $C$", "$f$", "$\\eta^{2}$", "$R^{2}$", "$f^{2}$"
  ),
  small = c(.20, .10, .05, .10, .01, .10, .10, .01, .02, .02),
  medium = c(.50, .30, .15, .30, .09, .30, .25, .06, .13, .15),
  large = c(.80, .50, .25, .50, .25, .50, .40, .14, .26, .35)
) |>
  gt() |>
  tab_options(table.font.size = pct(50)) |>
  cols_label(
    test = "Test",
    relevant_effect_size = "Relevant Effect Size",
    small = "Small",
    medium = "Medium",
    large = "Large"
  ) |>
  fmt_markdown(columns = relevant_effect_size) |>
  tab_spanner(
    label = "Effect Size Classes",
    columns = c(small, medium, large)
  ) |>
  tab_source_note(
    source_note = md(
      paste0(
        "Notes: The rationale for most of these benchmarks can be found ",
        "in Cohen (1988) at the following pages: Cohen‚Äôs $d$ (p. 40), ",
        "$q$ (p. 115), Cohen‚Äôs $g$ (pp. 147‚Äì149), $r$ and $r^{2}$ ",
        "(pp. 79‚Äì80), Cohen‚Äôs $w$ (pp. 224‚Äì227), $f$ and $\\eta^{2}$ ",
        "(pp. 285‚Äì287), $R^{2}$ and $f^{2}$ (pp. 413‚Äì414)."
      )
    )
  ) |>
  cols_align(
    align = "center",
    columns = c(small, medium, large)
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_spanners()
  ) |>
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(everything())
  )
```

::: footer
(Adapted from @ellis2010. Based on @cohen1988a)
:::

::: {.notes}
:::

## The *p*-value Problem: Example {.smaller}

::::: {.columns}
:::: {.column style="width: 45%; font-size: 0.9em;"}
$\Delta\text{R}^{2}$ = 0.00388`<br>`{=html}Cohen‚Äôs $f^{2}$ = 0.00414

Latitudinal cline of chronotype [@leocadio-miguel2017].

[Critique](https://danielvartan.github.io/mastersthesis/web/qmd/supplementary-material-9.html) of Leocadio-Miguel et al. latitude article [@vartanian2024a].

The ASA statement on p-values [@wasserstein2016].

Authors who rely solely on the p-value demonstrate a preference for statistical rituals over statistical reasoning [@gigerenzer2004].
::::
:::: {.column style="width: 55%;"}
![](images/leocadio-miguel-2017-figure-2.png){fig-align="center" style="width: 100%; padding-top: 25px;"}

::: {style="font-size: 0.5em; padding-left: 35px; padding-right: 15px;"}
**Note**: The HO score [@horne1976] goes from 16 to 86, with higher scores indicating a preference for morningness.
:::
::::
:::::

::: footer
(Reproduced from @leocadio-miguel2017[Figure 2])
:::

::: {.notes}
- **15-minute break** after this slide.
:::

## What Test Should I Use? {.smaller .nostretch}

Check Antoine Soetewey's [flowchart](https://statsandr.com/blog/what-statistical-test-should-i-do/) to help you decide the appropriate statistical test for your data.

![](images/soetewey-2021-flowchart.svg){fig-align="center" style="width: 65%; padding-top: 0px;"}

::: footer
(Artwork by [Antoine Soetewey](https://statsandr.com/blog/what-statistical-test-should-i-do/))
:::

::: {.notes}
:::

## The `infer` Package {.smaller .nostretch}

:::: {.columns}
::: {.column style="width: 15%; padding-top: 15px;"}
[![](images/infer-hex-logo.png){style="width: 120px;"}](https://infer.netlify.app)
:::
::: {.column style="width: 85%; padding-top: 15px;"}
[`infer`](https://infer.netlify.app) is a [Tidymodels](https://www.tidymodels.org/) package that provides a statistical **grammar** for inferential statistics.

```r
install.packages("infer")
```
:::
::::

It also offers [pipeline examples](https://infer.tidymodels.org/articles/observed_stat_examples.html) for various hypothesis tests. These pipelines can serve as a helpful starting point for implementing other types of models.

::: {.notes}
:::

## The `infer` Package {.smaller .nostretch}

![](images/couch-2021-figure-1.png){.nostretch fig-align="center" style="width: 75%; padding-top: 30px; padding-bottom: 10px;"}

:::: {.columns}
::: {.column style="width: 47.5%; font-size: 0.9em;"}
- [`specify()`](https://infer.netlify.app/reference/specify) specifies the variable, or relationship between variables, of interest.
- [`hypothesize()`](https://infer.netlify.app/reference/hypothesize) declares the null hypothesis.
- [`generate()`](https://infer.netlify.app/reference/generate) generates data reflecting the null hypothesis or using the bootstrap.
:::
::: {.column style="width: 5%;"}
:::
::: {.column style="width: 47.5%; font-size: 0.9em;"}
- [`calculate()`](https://infer.netlify.app/reference/calculate) calculates summary statistics from either the observed data to form the observed test statistic, or from the generated data to form the null distribution of test statistics.
- [`visualize()`](https://infer.netlify.app/reference/visualize) plots the null distribution of test statistics.
:::
::::

::: footer
[@couch2021]
:::

::: {.notes}
:::

## t-Test: Hypothesis {.smaller}

:::: {.columns}
::: {.column style="width: 50%; font-size: 0.85em;"}
[Is there a meaningful difference in body mass between male and female Adelie penguins?]{.brand-triad-blue-red .bold-black style="font-size: 1.1em;"}

Sexual dimorphism (physical differences between sexes) is common in many bird species. This could have implications for understanding their ecology and behavior.

To test this, we will perform a [t-Test for Independent Samples](https://statsandr.com/blog/student-s-t-test-in-r-and-by-hand-how-to-compare-two-groups-under-different-scenarios/) using a [randomization-based empirical null distribution](https://infer.netlify.app/reference/generate) approach.


Our test type-1 error rate ($\alpha$) will be set at **0.05** and our type-2 error rate ($\beta$) will be set at **0.2**, giving us a power of **0.8**.
:::
::: {.column style="width: 50%; padding-top: 130px;"}
$$
\begin{cases}
\text{H}_{0}: \mu_{A} = \mu_{B} \\
\text{H}_{a}: \mu_{A} \neq \mu_{B} \\
\end{cases}
$$

$$
\begin{cases}
\text{H}_{0}: \text{Cohen's d} < \text{MES} \\
\text{H}_{a}: \text{Cohen's d} \geq \text{MES} \\
\end{cases}
$$
:::
::::

::: {.notes}
:::

## t-Test: Hypothesis {.smaller}

::::: {.columns}
:::: {.column style="width: 50%; font-size: 0.85em;"}
[Is there a meaningful difference in body mass between male and female Adelie penguins?]{.brand-triad-blue-red .bold-black style="font-size: 1.1em;"}

To ensure [practical significance]{.underline}, we will analyze the difference in means for its effect size, considering a 95% confidence interval. Cohen's benchmark for a medium effect size (**d = 0.05**) will be used as our Minimum Effect Size (MES) [@cohen1988a].

::: {style="padding-top: 100px;"}
**Tip**: See @perezgonzalez2015 to learn more about data testing and practical significance.
:::
::::
:::: {.column style="width: 50%; padding-top: 130px;"}
$$
\begin{cases}
\text{H}_{0}: \mu_{A} = \mu_{B} \\
\text{H}_{a}: \mu_{A} \neq \mu_{B} \\
\end{cases}
$$

$$
\begin{cases}
\text{H}_{0}: \text{Cohen's d} < \text{MES} \\
\text{H}_{a}: \text{Cohen's d} \geq \text{MES} \\
\end{cases}
$$
::::
:::::

::: {.notes}
:::

## Cohen's d {.smaller}

::: {style="font-size: 0.95em;"}
Cohen's d is a measure of [effect size](https://en.wikipedia.org/wiki/Effect_size) that indicates the standardized difference between two means. When comparing two independent means, Cohen's d for [two tails](https://en.wikipedia.org/wiki/One-_and_two-tailed_tests) t-test can be calculated as:

$$
\text{d} = \frac{|\text{m}_{A} - \text{m}_{B}|}{s_{\text{pooled}}}
$$

Where:

- $\text{m}_{A}$ and $\text{m}_{B}$ are the sample means of the two groups.
- $s_{pooled}$ is the pooled standard deviation.
:::

::: footer
[@cohen1988a; @frey2022]
:::

::: {.notes}
:::

## Cohen's d {.smaller}

:::: {style="font-size: 0.95em;"}
The spooled standard deviation ($s_{pooled}$) is calculated using the following formula:

::: {style="padding-top: 15px; padding-bottom: 15px;"}
$$
s_{pooled} = \sqrt{\frac{(n_{1} - 1)s_{1}^{2} + (n_{2} - 1)s_{2}^{2}}{n_{1} + n_{2} - 2}}
$$
:::

Where:

- $n_{1}$ and $n_{2}$ are the sample sizes of the two groups.
- $s_{1}^{2}$ and $s_{2}^{2}$ are the sample variances of the two groups.
::::

::: footer
[@cohen1988a; @frey2022]
:::

::: {.notes}
:::

## The `pwr` and `pwrss` Packages {.smaller}

These two packages provide functions for performing power analysis and sample size calculations for various statistical tests, including [t-tests](https://en.wikipedia.org/wiki/Student%27s_t-test), [ANOVA](https://en.wikipedia.org/wiki/Analysis_of_variance), regression, and more.

:::: {.columns}
::: {.column style="width: 15%; padding-top: 15px;"}
[![](images/empty-hex-logo.svg){style="width: 120px;"}](https://CRAN.R-project.org/package=pwr)
:::
::: {.column style="width: 85%; padding-top: 15px;"}
[`pwr`](https://CRAN.R-project.org/package=pwr) provides basic functions for power analysis.

```r
install.packages("pwr")
```
:::
::::

:::: {.columns}
::: {.column style="width: 15%;"}
[![](images/pwrss-hex-logo.png){style="width: 120px;"}](https://cran.r-project.org/web/packages/pwrss/vignettes/examples.html)
:::
::: {.column style="width: 85%; padding-top: 15px;"}
[`pwrss`](https://cran.r-project.org/web/packages/pwrss/vignettes/examples.html) provides functions to perform power and sample size calculations for various statistical tests.

```r
install.packages("pwrss")
```
:::
::::

::: {.notes}
:::

## t-Test: Power Analysis {.smaller}

The [power](https://en.wikipedia.org/wiki/Power_(statistics)) ($1 - \beta$) of a statistical test is the probability that it will yield statistically significant results [@cohen1988a].

A power analysis helps determine the minimum sample size required to detect an effect of a given size with a desired level of confidence [@cohen1988a]. We need to check if our sample size will be sufficient to achieve this confidence.

::: {style="padding-top: 15px;"}
```{r}
library(dplyr)
library(palmerpenguins)
library(tidyr)
```

```{r}
penguins |>
  filter(species == "Adelie") |>
  drop_na(body_mass_g, sex) |>
  count(sex)
```
:::

::: {.notes}
:::

## t-Test: Power Analysis {.smaller}

A power analysis for a t-test with an expected effect size of $\text{d} = 0.5$ indicates that we would need approximately [64]{.brand-triad-blue-red .bold-black} participants in each group to achieve a power of **0.8** at a significance level of **0.05**.

:::: {.columns}
::: {.column style="width: 47.5%; padding-top: 15px;"}
```{r}
library(pwr)
```

```{r}
#| eval: false
#| include: false

power.t.welch(
  d = 0.50,
  power = 0.80,
  alpha = 0.05,
  alternative = "two.sided"
)
```

```{r}
pwr_analysis <- pwr.t.test(
  d = 0.5,
  sig.level = 0.05,
  power = 0.8,
  type = "two.sample",
  alternative = "two.sided"
)
```
:::
::: {.column style="width: 5%;"}
:::
::: {.column style="width: 47.5%; padding-top: 15px;"}
```{r}
pwr_analysis
```
:::
::::

::: {.notes}
:::

## t-Test: Power Analysis {.smaller .nostretch}

```{r}
#| code-fold: true
#| warning: false
#| fig-align: center

library(pwr)

pwr_analysis |>
  plot.power.htest(
    xlab = "Sample Size Per Group",
    ylab = "Power (1 - Beta)",
    main = NULL
  )
```

::: {.notes}
:::

## t-Test: Power Analysis {.smaller .nostretch}

```{r}
#| code-fold: true
#| warning: false
#| fig-align: center

library(pwrss)

pwr_analysis <- pwrss.t.2means(
  mu1 = 0.5,
  mu2 = 0,
  power = 0.8,
  alpha = 0.05,
  welch.df = TRUE,
  alternative = "not equal"
)

power.t.test(
  ncp = pwr_analysis$ncp,
  df = pwr_analysis$df,
  alpha = pwr_analysis$parms$alpha,
  alternative = "two.sided",
  plot = TRUE,
  verbose = FALSE
)
```

::: {.notes}
:::

## t-Test: Assumptions {.smaller}

üîó Independence of observations.

::: {style="padding-top: 15px;"}
üîî Normality of the distribution of the response variable (`body_mass_g`) within each group (`sex` is the explanatory/independent variable).
:::

::: {style="padding-top: 15px;"}
‚öñÔ∏è Homogeneity of variances (equal variances) between groups (only if using Student's t-test; [Welch's t-test](https://en.wikipedia.org/wiki/Welch%27s_t-test) and our permutation approach do not require this assumption).
:::

::: footer
[@howell2013]
:::

::: {.notes}
:::

## t-Test: Boxplots {.smaller .nostretch}

```{r}
#| eval: false
#| code-fold: true

library(dplyr)
library(ggplot2)
library(palmerpenguins)
library(tidyr)

penguins |>
  filter(species == "Adelie") |>
  drop_na(
    body_mass_g,
    sex
  ) |>
  ggplot(
    aes(
      x = sex,
      y = body_mass_g,
      fill = sex
    )
  ) +
  geom_boxplot(outlier.color = "red") +
  geom_jitter(
    width = 0.2,
    alpha = 0.1
  ) +
  labs(
    x = "Sex",
    y = "Body Mass (g)",
    fill = "Sex"
  )
```

```{r}
#| echo: false
#| warning: false
#| fig-align: center

library(brandr)
library(dplyr)
library(ggplot2)
library(palmerpenguins)
library(tidyr)

penguins |>
  filter(species == "Adelie") |>
  drop_na(
    body_mass_g,
    sex
  ) |>
  ggplot(
    aes(
      x = sex,
      y = body_mass_g,
      fill = sex
    )
  ) +
  geom_boxplot(outlier.color = "red") +
  geom_jitter(
    width = 0.2,
    alpha = 0.1
  ) +
  scale_fill_brand_d(alpha = 0.7) +
  labs(
    x = "Sex",
    y = "Body Mass (g)",,
    fill = "Sex"
  )
```

::: {.notes}
:::

## t-Test: Histograms {.smaller .nostretch}

```{r}
#| eval: false
#| code-fold: true

library(dplyr)
library(ggplot2)
library(palmerpenguins)
library(tidyr)

penguins |>
  filter(species == "Adelie") |>
  drop_na(
    body_mass_g,
    sex
  ) |>
  ggplot(
    aes(
      x = body_mass_g,
      fill = sex
    )
  ) +
  geom_histogram(
    position = "identity",
    alpha = 0.7
  ) +
  labs(
    x = "Body Mass (g)",,
    y = "Frequency",
    fill = "Sex"
  )
```

```{r}
#| echo: false
#| warning: false
#| fig-align: center

library(brandr)
library(dplyr)
library(ggplot2)
library(palmerpenguins)
library(tidyr)

penguins |>
  filter(species == "Adelie") |>
  drop_na(
    body_mass_g,
    sex
  ) |>
  ggplot(
    aes(
      x = body_mass_g,
      fill = sex
    )
  ) +
  geom_histogram(
    position = "identity",
    alpha = 0.7
  ) +
  scale_fill_brand_d() +
  labs(
    x = "Body Mass (g)",,
    y = "Frequency",
    fill = "Sex"
  )
```

::: {.notes}
:::

## t-Test: Density Plots {.smaller .nostretch}

```{r}
#| eval: false
#| code-fold: true

library(dplyr)
library(ggplot2)
library(palmerpenguins)
library(tidyr)

penguins |>
  filter(species == "Adelie") |>
  drop_na(
    body_mass_g,
    sex
  ) |>
  ggplot(
    aes(
      x = body_mass_g,
      fill = sex
    )
  ) +
  geom_density(alpha = 0.7) +
  labs(
    x = "Body Mass (g)",,
    y = "Density",
    fill = "Sex"
  )
```

```{r}
#| echo: false
#| warning: false
#| fig-align: center

library(brandr)
library(dplyr)
library(ggplot2)
library(palmerpenguins)
library(tidyr)

penguins |>
  filter(species == "Adelie") |>
  drop_na(
    body_mass_g,
    sex
  ) |>
  ggplot(
    aes(
      x = body_mass_g,
      fill = sex
    )
  ) +
  geom_density(alpha = 0.7) +
  scale_fill_brand_d() +
  labs(
    x = "Body Mass (g)",,
    y = "Density",
    fill = "Sex"
  )
```

::: {.notes}
:::

## t-Test: Q-Q Plots {.smaller .nostretch}

```{r}
#| eval: false
#| code-fold: true

library(brandr)
library(dplyr)
library(ggplot2)
library(palmerpenguins)
library(tidyr)

penguins |>
  filter(species == "Adelie") |>
  drop_na(
    body_mass_g,
    sex
  ) |>
  ggplot(
    aes(
      sample = body_mass_g,
      color = sex
    )
  ) +
  stat_qq() +
  stat_qq_line(color = "black") +
  facet_wrap(vars(sex)) +
  labs(
    x = "Theoretical Quantiles",
    y = "Sample Quantiles",
    color = "Sex"
  )
```

```{r}
#| echo: false
#| warning: false
#| fig-align: center

library(brandr)
library(dplyr)
library(ggplot2)
library(palmerpenguins)
library(tidyr)

penguins |>
  filter(species == "Adelie") |>
  drop_na(
    body_mass_g,
    sex
  ) |>
  ggplot(
    aes(
      sample = body_mass_g,
      color = sex
    )
  ) +
  stat_qq() +
  stat_qq_line(color = get_brand_color("black")) +
  scale_color_brand_d() +
  facet_wrap(vars(sex)) +
  labs(
    x = "Theoretical Quantiles",
    y = "Sample Quantiles",
    color = "Sex"
  )
```

::: {.notes}
:::

## t-Test: Assumptions {.smaller}

‚úÖ Independence of observations.

::: {style="padding-top: 15px;"}
‚úÖ Normality of the distribution of the response variable (`body_mass_g`) within each group (`sex` is the explanatory/independent variable).
:::

::: {style="padding-top: 15px;"}
‚è≠Ô∏è Homogeneity of variances (equal variances) between groups (only if using Student's t-test; [Welch's t-test](https://en.wikipedia.org/wiki/Welch%27s_t-test) and our permutation approach do not require this assumption).
:::

::: {.notes}
:::

## t-Test: Observed Statistic {.smaller}

The [t-statistic](https://en.wikipedia.org/wiki/T-statistic) for comparing two independent means can be calculated using the following formula:

$$
t = \frac{\text{m}_{A} - \text{m}_{B}}{\sqrt{\frac{s_{A}^{2}}{n_{A}} + \frac{s_{B}^{2}}{n_{B}}}}
$$

Where:

- $\text{m}_{A}$ and $\text{m}_{B}$ are the sample means of the two groups.
- $s_{A}^{2}$ and $s_{B}^{2}$ are the sample variances of the two groups.
- $n_{A}$ and $n_{B}$ are the sample sizes of the two groups.

::: footer
[@frey2022, p. 1671]
:::

::: {.notes}
:::

## t-Test: Observed Statistic {.smaller}

:::: {.columns}
::: {.column style="width: 50%;"}
```{r}
library(dplyr)
library(magrittr)
library(palmerpenguins)
library(tidyr)
```

```{r}
male <-
  penguins |>
  filter(
    species == "Adelie",
    sex == "male"
  ) |>
  drop_na() |>
  pull(body_mass_g)
```

```{r}
female <-
  penguins |>
  filter(
    species == "Adelie",
    sex == "female"
  ) |>
  drop_na() |>
  pull(body_mass_g)
```
:::
::: {.column style="width: 50%;"}
```{r}
t_statistic <-
  mean(male, na.rm = TRUE) |>
  subtract(mean(female, na.rm = TRUE)) |>
  divide_by(
    var(male, na.rm = TRUE) |>
      divide_by(length(male)) |>
      add(
        var(female, na.rm = TRUE) |>
          divide_by(length(female))
      ) |>
      sqrt()
  )
```

```{r}
t_statistic
```
:::
::::

```{r}
#| eval: false
#| include: false

penguins |>
  t.test(
    body_mass_g ~ sex,
    data = _,
    subset = species == "Adelie"
  )
```

::: {.notes}
:::

## t-Test: Observed Statistic {.smaller}

```{r}
library(dplyr)
library(infer)
library(palmerpenguins)
library(tidyr)
```

```{r}
observed_statistic <-
  penguins |>
  filter(species == "Adelie") |>
  drop_na(body_mass_g, sex) |>
  specify(body_mass_g ~ sex) |>
  hypothesize(null = "independence") |>
  calculate(
    stat = "t",
    order = c("male", "female")
  )
```

```{r}
observed_statistic
```

::: {.notes}
:::

## t-Test: Null Distribution {.smaller}

::: {style="padding-top: 30px; padding-bottom: 30px; text-align: center;"}
[What would our data look like if there was no difference between sexes?]{.brand-triad-blue-red .bold-black style="font-size: 1.1em;"}
:::

One way to simulate this scenario is to randomly shuffle the `sex` values among the `body_mass_g` values. This breaks any real association between sex and body mass.

We then calculate the t-statistic for this new dataset. Repeating this process many times allows us to build a distribution of t-statistics that represent what we would expect to see if there were no real difference in body mass between male and female Adelie penguins.

::: {.notes}
:::

## t-Test: Null Distribution {.smaller}

:::: {.columns}
::: {.column style="width: 50%;"}
```{r}
library(dplyr)
library(infer)
library(palmerpenguins)
library(tidyr)
```

```{r}
null_dist <-
  penguins |>
  filter(species == "Adelie") |>
  drop_na(body_mass_g, sex) |>
  specify(body_mass_g ~ sex) |>
  hypothesize(null = "independence") |>
  generate(
    reps = 1000,
    type = "permute"
  ) |>
  calculate(
    stat = "t",
    order = c("male", "female")
  )
```
:::
::: {.column style="width: 50%;"}
```{r}
null_dist
```
:::
::::

::: {.notes}
:::

## t-Test: Visualizing {.smaller .nostretch}

```{r}
#| code-fold: true
#| fig-align: center
#| fig-height: 7
#| fig-width: 15

library(infer)
library(ggplot2)

null_dist |>
  visualize() +
  shade_p_value(
    obs_stat = observed_statistic,
    direction = "two-sided"
  ) +
  labs(
    title = NULL,
    x = "t-statistic",
    y = "Frequency"
  ) +
  theme(
    text = element_text(size = 14)
  )
```

::: {.notes}
:::

## t-Test: p-value {.smaller}

```{r}
#| warning: false

null_dist |>
  get_p_value(
    obs_stat = observed_statistic,
    direction = "two-sided"
  )
```

::: {.notes}
:::

## t-Test: Observed Effect Size {.smaller}

:::: {.columns}
::: {.column style="width: 50%;"}
```{r}
library(dplyr)
library(effectsize)
library(palmerpenguins)
library(tidyr)
```

```{r}
male <-
  penguins |>
  filter(
    species == "Adelie",
    sex == "male"
  ) |>
  drop_na() |>
  pull(body_mass_g)
```

```{r}
female <-
  penguins |>
  filter(
    species == "Adelie",
    sex == "female"
  ) |>
  drop_na() |>
  pull(body_mass_g)
```
:::
::: {.column style="width: 50%;"}
```{r}
effect_size <-
  cohens_d(
    x = male,
    y = female,
    mu = 0,
    ci = 0.95,
    alternative = "two.sided"
  )
```

```{r}
effect_size
```
```{r}
effect_size |>
  interpret_hedges_g(rules = "cohen1988")
```
:::
::::

::: {.notes}
:::

## t-Test: Conclusion {.smaller}

:::: {.columns}
::: {.column style="width: 60%; font-size: 0.85em;"}
[Is there a meaningful difference in body mass between male and female Adelie penguins?]{.brand-triad-blue-red .bold-black style="font-size: 1.1em;"}

Our analysis found a statistically significant difference in means ($t$ = 13.1, $p$-value < 0.001). The observed effect size was large and exceed the Minimal Effect Size (MES) threshold ($d$ = 2.17, 95% CI [1.76, 2.58]).

Since we could reliably detect effects of **d = 0.5** or larger, the power of our test remains high, indicating that the probability of a false negative ($\beta$) is very low.

Based on these results, we conclude that **there is a meaningful difference in body mass between male and female Adelie penguins**, with male penguins having a higher mean body mass. Therefore, we reject the null hypothesis in favor of the alternative hypothesis.
:::
::: {.column style="width: 40%; padding-top: 130px;"}
$$
\begin{cases}
\text{H}_{0}: \mu_{A} = \mu_{B} \\
\text{H}_{a}: \mu_{A} \neq \mu_{B} \\
\end{cases}
$$

$$
\begin{cases}
\text{H}_{0}: d < \text{MES} \\
\text{H}_{a}: d \geq \text{MES} \\
\end{cases}
$$
:::
::::

::: {.notes}
- **15-minute break** after this slide.
:::

## Model Diagnostics {.smaller}

:::: {.columns}
::: {.column style="width: 47.5%;"}
[Model diagnostics are crucial!]{.brand-triad-blue-red .bold-black}

It's essential to verify that all model assumptions hold. However, a discussion on this topic is beyond the scope of this course.

You can find these assumptions in most statistical textbooks, or you can look at the original papers that introduced the models (e.g., fot t-Tests, see @student1908).
:::
::: {.column style="width: 5%;"}
:::
::: {.column style="width: 47.5%;"}
![](images/allison-horst-figure-38.png){fig-align="center" style="width: 90%; padding-top: 100px;"}
:::
::::

::: footer
(Artwork by [Allison Horst](https://twitter.com/allison_horst))
:::

::: {.notes}
:::

## Objective Assumption Tests {.smaller}

üö® **Avoid Using!** üö®

Objective assumption tests (e.g., Anderson‚ÄìDarling test) are not advisable for large samples, as they can be overly sensitive to minor deviations. Additionally, they might overlook visual patterns that are not captured by a single metric.

Usually, a visual inspection of the data is the preferred approach in most cases.

For a straightforward critique of normality tests specifically, refer to [this](https://towardsdatascience.com/stop-testing-for-normality-dba96bb73f90) article by @greener2020.

See also: @kozak2018, @schucany2006, and @shatz2024.

::: {.notes}
:::

## How to Learn More {.smaller}

:::: {.columns}
::: {.column style="width: 47.5%;"}
[![](images/degroot-2012-book-cover.jpg){fig-align="center" style="width: 85%;"}](https://books.google.com.br/books/about/Probability_and_Statistics.html?id=4TlEPgAACAAJ&redir_esc=y)
:::
::: {.column style="width: 5%;"}
:::
::: {.column style="width: 47.5%;"}
[![](images/kuhn-2022-book-cover.jpg){fig-align="center" style="width: 83%;"}](https://www.tmwr.org/)
:::
::::

::: footer
(Book cover image from @degroot2012a and @kuhn2022)
:::

::: {.notes}
:::

## How to Learn More {.smaller}

:::: {.columns}
::: {.column style="width: 50%; text-align: center; padding-top: 50px;"}
[![](images/statquest-logo.jpg){fig-align="center" style="width: 50%; border-radius:50%; border:1px solid black;"}](https://www.youtube.com/c/joshstarmer)

**StatQuest**`<br>`{=html}by Josh Starmer
:::
::: {.column style="width: 50%; text-align: center; padding-top: 50px;"}
[![](images/very-normal-logo.png){fig-align="center" style="width: 50%; border-radius:50%; border:1px solid black;"}](https://www.youtube.com/@very-normal)

**Very Normal**`<br>`{=html}by Christian Pascual
:::
::::

::: {.notes}
- **15-minute break** or **day end** after this slide.
:::
